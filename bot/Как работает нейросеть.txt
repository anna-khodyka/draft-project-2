Как работает нейросеть нашего приложения:

1. Сначала мы создали набор данных, с помощью которого натренируем нейросеть распознавать команды. 
Приведу пример для 2 похожих команд:


 {"tag": "add contact",
  "patterns": ["new contact", "new record", "new user","add record", "create contact", "new phone", "add contact", "new number", "add frend", "new number", "new account", "save contact", "save phone"],
   },
 {"tag":"edit contact",
 "patterns": ["update contact", "update record", "update phone", "update email", "edit contact", "edit record", "change record",  "new email", "new address", "add details", "edit details", "add birthday", "edit name", "change conact", "edit account", "edit birthday"],
  }

Т.е. ключ "patterns" хранит список всех возможных вариаций, синонимов команды, указанной в ключе "tag".

И так для всех команд, которыми оперирует бот. Так мы сформировали тренировочный dataset, 
где входными данными будут слова, хранящиеся по ключу "response" а выходными - команды  в ключах "tag".

2. Далее, используя функции tokenizer и lemmatizer мы все слова приводим к специальному виду, отбрасывая приставки, окончания, знаки препинания и т.д.

3. Все слова (вообще все, из pattern для всех команд) мы складываем в одно упорядоченное множество: 
все дублирующиеся слова выброшены, слова отсортированы по алфавиту. Назовем это множество "набор слов".

4. Теперь, для любой команды в нашем тренинговом наборе из паттернов команды можно создать вектор 
из 0 и 1, где длинна вектора = длинна "набора слов", в этом векторе 1 стоят только на тех позициях, 
которые соответствуют расположению слов из паттерна в наборе слов.
Предположим, что мы имеем только один паттерн для команды: "add zip". 
В таком случае наш вектор может выглядеть "1 0 0 0....0 0 1" 
(чисто гипотетически полагаю, что слова на "a" и "z" окажутся на концах "набора слов")


5. Построим матрицу из паттернов размерности длинна(набора слов) Х количество(tag) - 
обучающая матрица на входе в нейросеть, и вектор "ответов",
который содержит нумерацию tags, т.е. (1,2....количество tag). 
Каждой строке в матрице будет соответствовать 1 значение в векторе.

6. Используя библиотеку keras создадим нейросеть:
 128 узлов первый слой  | 64 узла второй слой | количество узлов = количество (tag) третий слой
Почему именно такое количество узлов? Чисто экспериментально. 
Меньше - падает точность, больше - долго обрабатываютя команды.

7. Передадим нейросети наш тренинговый дата сет: обучающуя матрицу и вектор "ответов", тренируем ее и создадим модель прогнозирования.
Математический смысл такой: 
будет создана модель матричных преобразований, которая любой вектор из поданных на вход (вектор включений в набор слов) 
с максимальной вероятностью приведет к значению, соответствующему искомому tag.


Все эти действия выполняются еще на этапе разработки приложения. 
Модель не меняется в ходе работы приложения и не дообучается самостоятельно.


8. Далее, в нашем приложении, мы работаем используя уже построенную модель.
Как это происходит: мы передаем в нейросеть вектор, посторенный на основе команды пользователя 
и нашего набора слов из обучающего набора. Вектор состоит из 0 и 1. Строится по тому же принципу, что и при обучении нейросети:
1 на тех позициях где в наборе слов находятся слова из команды пользователя. 
Нейросеть вернет нам номер tags, которым соответсвует такой вектор, 
отсортированные по убыванию вероятности правильного ответа.
Если в команде пользователя не было слов из нашего набора слов, либо таких слов слишком мало, 
чтобы с вероятностью выше ERROR_TRESHOLD определить, какая команда им соответствует, 
нейросеть вернет пустой список ответов. 
В таком случае мы предложим пользователю почитать help и точнее сформулировать запрос.


9. Если от нейросети пришел не пустой список, нам остается взять ответ, имеющий наибольшую вероятность 
и запутистить соответствующую ему функцию (web view) в приложении.
 


 
 

